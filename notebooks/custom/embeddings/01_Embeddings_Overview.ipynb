{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Service Notebook\n",
    "\n",
    "This is the first custom notebook to document and test how Aurite will use txtai's features.\n",
    "\n",
    "The first three notebooks (including this one) will focus on the functionality of txtai's embeddings service.\n",
    "\n",
    "This service will be used to embed and manage documents. It is the central component of txtai.\n",
    "\n",
    "We will start by setting up the embeddings service with a basic configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1 - Imports and Setup\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from txtai.embeddings import Embeddings\n",
    "import logging\n",
    "\n",
    "# Setup logging with a clear format\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Setup\n",
    "\n",
    "This is the basic configuration for the embeddings service.\n",
    "\n",
    "The embeddings service, which is a wrapper around the txtai embeddings library, is configured with a minimal set of parameters.\n",
    "\n",
    "The txtai embeddings library is configured with a model, content storage, vector storage backend, hybrid search, and normalization.\n",
    "\n",
    "This configuration is used to initialize the embeddings service. NOTE: This is not the final configuration, but a starting point to test the embeddings service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:47:37,296 - INFO - Initializing embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - Basic Configuration\n",
    "# Create a minimal embeddings config to start\n",
    "config = {\n",
    "    \"path\": \"sentence-transformers/nli-mpnet-base-v2\",  # Model choice\n",
    "    \"content\": True,                                    # Enable content storage\n",
    "    \"backend\": \"faiss\",                                # Vector storage backend\n",
    "    \"hybrid\": True,                                    # Enable hybrid search\n",
    "    \"normalize\": True                                  # Normalize vectors\n",
    "}\n",
    "\n",
    "# Initialize embeddings\n",
    "logger.info(\"Initializing embeddings...\")\n",
    "embeddings = Embeddings(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3 - Test Documents\n",
    "\n",
    "Next, we will create some test documents to use for testing the embeddings service.\n",
    "\n",
    "After creating the test documents, we will index them into the embeddings service.\n",
    "\n",
    "This is how you add documents to the embeddings service.\n",
    "\n",
    "Indexing involves embedding the documents and storing them in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:47:38,241 - INFO - Indexing test documents...\n",
      "2024-11-17 16:47:38,400 - INFO - Total documents indexed: 5\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - Test Documents\n",
    "import json\n",
    "\n",
    "# Create test documents with different formats\n",
    "test_docs = [\n",
    "    # Basic documents (id, text, tags)\n",
    "    (0, \"This is a test document about machine learning\", None),\n",
    "    (1, \"Another document about cloud computing\", None),\n",
    "    (2, \"Document about natural language processing\", None),\n",
    "\n",
    "    # Documents with metadata - convert dict to JSON string\n",
    "    (3, \"Document about vector databases\",\n",
    "     json.dumps({\"category\": \"databases\", \"type\": \"technical\"})),\n",
    "    (4, \"Introduction to embeddings\",\n",
    "     json.dumps({\"category\": \"ml\", \"type\": \"introduction\"}))\n",
    "]\n",
    "\n",
    "# Index documents\n",
    "logger.info(\"Indexing test documents...\")\n",
    "embeddings.index(test_docs)\n",
    "logger.info(f\"Total documents indexed: {embeddings.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4 - Understanding Result Formats\n",
    "\n",
    "In this section, we will test the basic search functionality of the embeddings service.\n",
    "\n",
    "Before we display the results, we will create a utility function to inspect the results so we can understand the data structure.\n",
    "\n",
    "These structures are finicky, so it is important to test and document them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:47:38,434 - INFO - \n",
      "Basic Search Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:47:38,434 - INFO - Result type: <class 'list'>\n",
      "2024-11-17 16:47:38,434 - INFO - First result type: <class 'dict'>\n",
      "2024-11-17 16:47:38,435 - INFO - First result content: {'id': '0', 'text': 'This is a test document about machine learning', 'score': 0.6211893865296524}\n",
      "2024-11-17 16:47:38,435 - INFO - Available keys: dict_keys(['id', 'text', 'score'])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Understanding Result Formats\n",
    "def inspect_results(results, label=\"Search Results\"):\n",
    "    \"\"\"Utility function to inspect search result format\"\"\"\n",
    "    logger.info(f\"\\n{label}\")\n",
    "    logger.info(f\"Result type: {type(results)}\")\n",
    "    if results:\n",
    "        logger.info(f\"First result type: {type(results[0])}\")\n",
    "        logger.info(f\"First result content: {results[0]}\")\n",
    "        if isinstance(results[0], tuple):\n",
    "            logger.info(\"Format: (id, score) tuple\")\n",
    "        elif isinstance(results[0], dict):\n",
    "            logger.info(f\"Available keys: {results[0].keys()}\")\n",
    "    return results\n",
    "\n",
    "# Test basic search\n",
    "basic_results = inspect_results(\n",
    "    embeddings.search(\"machine learning\", 2),\n",
    "    \"Basic Search Results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5 - Search Result Processing\n",
    "\n",
    "This is where we process the results returned by the embeddings service. \n",
    "\n",
    "We will use the utility function we created earlier to inspect the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:47:38,441 - INFO - \n",
      "Processing Search Results:\n",
      "2024-11-17 16:47:38,442 - INFO - Text: This is a test document about machine learning\n",
      "2024-11-17 16:47:38,443 - INFO - Score: 0.6211893865296524\n",
      "2024-11-17 16:47:38,443 - INFO - ---\n",
      "2024-11-17 16:47:38,444 - INFO - Text: Document about natural language processing\n",
      "2024-11-17 16:47:38,444 - INFO - Score: 0.1778886765241623\n",
      "2024-11-17 16:47:38,445 - INFO - ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Search Result Processing (updated)\n",
    "logger.info(\"\\nProcessing Search Results:\")\n",
    "for result in basic_results:\n",
    "    # Handle dictionary format\n",
    "    logger.info(f\"Text: {result['text']}\")\n",
    "    logger.info(f\"Score: {result['score']}\")\n",
    "\n",
    "    # Look up original document for metadata\n",
    "    doc_id = int(result['id'])\n",
    "    if doc_id < len(test_docs):\n",
    "        original_doc = test_docs[doc_id]\n",
    "        if original_doc[2]:  # metadata is at index 2\n",
    "            try:\n",
    "                metadata = json.loads(original_doc[2])\n",
    "                logger.info(f\"Metadata: {metadata}\")\n",
    "            except json.JSONDecodeError:\n",
    "                logger.info(f\"Raw Metadata: {original_doc[2]}\")\n",
    "    logger.info(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6 - Different Search Types\n",
    "\n",
    "This section is used to compare the different search types available in the embeddings service.\n",
    "\n",
    "We will test the basic search and the hybrid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:47:38,454 - INFO - \n",
      "Comparing Search Types:\n",
      "2024-11-17 16:47:38,454 - INFO - \n",
      "Query: machine learning\n",
      "2024-11-17 16:47:38,475 - INFO - Basic Search Score: 0.6211893865296524\n",
      "2024-11-17 16:47:38,476 - INFO - Basic Search Text: This is a test document about machine learning\n",
      "2024-11-17 16:47:38,495 - INFO - Hybrid Search Score: 0.6211893865296524\n",
      "2024-11-17 16:47:38,495 - INFO - Hybrid Search Text: This is a test document about machine learning\n",
      "2024-11-17 16:47:38,495 - INFO - ---\n",
      "2024-11-17 16:47:38,496 - INFO - \n",
      "Query: cloud storage\n",
      "2024-11-17 16:47:38,517 - INFO - Basic Search Score: 0.5902987615700078\n",
      "2024-11-17 16:47:38,518 - INFO - Basic Search Text: Another document about cloud computing\n",
      "2024-11-17 16:47:38,534 - INFO - Hybrid Search Score: 0.5902987615700078\n",
      "2024-11-17 16:47:38,534 - INFO - Hybrid Search Text: Another document about cloud computing\n",
      "2024-11-17 16:47:38,534 - INFO - ---\n",
      "2024-11-17 16:47:38,535 - INFO - \n",
      "Query: vector database\n",
      "2024-11-17 16:47:38,557 - INFO - Basic Search Score: 0.666651775933202\n",
      "2024-11-17 16:47:38,557 - INFO - Basic Search Text: Document about vector databases\n",
      "2024-11-17 16:47:38,585 - INFO - Hybrid Search Score: 0.666651775933202\n",
      "2024-11-17 16:47:38,585 - INFO - Hybrid Search Text: Document about vector databases\n",
      "2024-11-17 16:47:38,586 - INFO - ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 - Different Search Types\n",
    "# Compare different search approaches\n",
    "queries = [\n",
    "    \"machine learning\",\n",
    "    \"cloud storage\",\n",
    "    \"vector database\"\n",
    "]\n",
    "\n",
    "logger.info(\"\\nComparing Search Types:\")\n",
    "for query in queries:\n",
    "    logger.info(f\"\\nQuery: {query}\")\n",
    "\n",
    "    # Basic search\n",
    "    basic = embeddings.search(query, 1)\n",
    "    logger.info(f\"Basic Search Score: {basic[0]['score']}\")  # Using dictionary key 'score'\n",
    "    logger.info(f\"Basic Search Text: {basic[0]['text']}\")\n",
    "\n",
    "    # Hybrid search (combines semantic + BM25)\n",
    "    hybrid = embeddings.search(query, 1)\n",
    "    logger.info(f\"Hybrid Search Score: {hybrid[0]['score']}\")  # Using dictionary key 'score'\n",
    "    logger.info(f\"Hybrid Search Text: {hybrid[0]['text']}\")\n",
    "    logger.info(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7 - Switch Embeddings Config\n",
    "\n",
    "With .load(config) we can use the same embeddings object with a different configuration.\n",
    "\n",
    "This is useful to test different configurations without having to re-initialize the embeddings service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:48:19,302 - INFO - Initializing new embeddings configuration...\n",
      "2024-11-17 16:48:19,660 - INFO - Re-indexing test documents with new configuration...\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 - Switch Embeddings Config\n",
    "new_config = {\n",
    "    \"path\": \"sentence-transformers/nli-mpnet-base-v2\",\n",
    "    \"content\": False,\n",
    "    \"backend\": \"faiss\",\n",
    "    \"hybrid\": True,\n",
    "    \"normalize\": True\n",
    "}\n",
    "\n",
    "# Create new embeddings instance with new config\n",
    "logger.info(\"Initializing new embeddings configuration...\")\n",
    "new_embeddings = Embeddings(new_config)\n",
    "\n",
    "# Re-index the test documents with new configuration\n",
    "logger.info(\"Re-indexing test documents with new configuration...\")\n",
    "new_embeddings.index(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:48:22,465 - INFO - \n",
      "New Configuration Search Results\n",
      "2024-11-17 16:48:22,469 - INFO - Result type: <class 'list'>\n",
      "2024-11-17 16:48:22,469 - INFO - First result type: <class 'dict'>\n",
      "2024-11-17 16:48:22,470 - INFO - First result content: {'id': '0', 'text': 'This is a test document about machine learning', 'score': 0.6211893865296524}\n",
      "2024-11-17 16:48:22,470 - INFO - Available keys: dict_keys(['id', 'text', 'score'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text': 'This is a test document about machine learning',\n",
       "  'score': 0.6211893865296524}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the new configuration\n",
    "new_results = embeddings.search(\"machine learning\", 1)\n",
    "inspect_results(new_results, \"New Configuration Search Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook is a guide to understanding how we can use txtai's embeddings functionality through our embeddings service.\n",
    "\n",
    "We have tested the basic search and the hybrid search.\n",
    "\n",
    "We have also inspected the results and processed them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txtai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
